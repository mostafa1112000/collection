///////// classfction/////////////
import pandas as pd
data = pd.read_csv('classfiction.csv')
x=data.drop('outcome',1)
y=data['outcome']
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)
print(data)
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators =10)
rf.fit(x_train,y_train)

predictions = rf.predict(x_test)

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(y_test,predictions)
print(matrix)

from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test,predictions)
print('accuracy_score =',acc)







///////////////// k-fold///////////


import pandas as pd 
data=pd.read_csv('classfiction.csv') 
X=data.drop('outcome',1)
y=data['outcome']
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier


rf = RandomForestClassifier(n_estimators = 10)

from sklearn.model_selection import KFold
k=5
kfold =KFold(n_splits=k, random_state=None, shuffle=False)

acclist=[]


for train_index, test_index in kfold.split(X):
    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]
    y_train , y_test = y[train_index] , y[test_index]
    rf.fit(X_train, y_train)
    predictions = rf.predict(X_test)
    
    from sklearn.metrics import confusion_matrix
    matrix = confusion_matrix(y_test, predictions)
    
    
    from sklearn.metrics import accuracy_score
    acc=accuracy_score(y_test,predictions)
    acclist.append(acc)
    
acc=sum(acclist)/k
print(acc)



///////////////////////linerregrtion///////////////////////


import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
dataset = pd.read_csv('beatsdataset_full.csv')
dataset.shape
dataset.head()



x = dataset.iloc[:, :-2].values
y = dataset.iloc[:, 1].values

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.4, random_state=0)

print(x_test)
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(x_train, y_train)
print("intercept",regressor.intercept_)
print("cof",regressor.coef_)
y_pred = regressor.predict(x_test)
df = pd.DataFrame({'Actual': y_test, 'predicted': y_pred})
print(df)

from sklearn import metrics
print('Mean Absolut Error', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squard Error', metrics.mean_squared_error(y_test, y_pred))
print('Root Squard Error', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))


dataset.plot(x='Hours', y='scores', style='o')
plt.title('Hours vs percentage')
plt.xlabel('Hours studied')
plt.ylabel('precentage score')
plt.plot(x_test, y_pred, color="blue", linewidth=3)
plt.show()




/////////////////////////////pca///////////


import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
df=pd.read_csv('classfiction.csv') #dataframe
X=df.drop('outcome',1)
y=df['outcome']


pca = PCA(n_components=5)
principalComponents = pca.fit_transform(X)
principalDf = pd.DataFrame(data = principalComponents
           , columns = ['A', 'B','C','D','E'])
finalDf = pd.concat([principalDf,y], axis = 1)



finalDf.to_csv("mostafa.csv",index = False, header=True)
exvar= pca.explained_variance_ratio_
cexvarsum = np.cumsum(exvar)
print(exvar)
plt.bar(range(0,len(exvar)), exvar, label='Individual explained variance')
plt.step(range(0,len(cexvarsum)), cexvarsum ,label='Cumulative explained variance')
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal component index')
plt.legend(loc='lower right')

mask=data.isnull()
print(mask)
plt.show()



///////////////////////////////////

#recall 
from sklearn.metrics import recall_score
rec=recall_score(y_test,predictions)
print("recall  ",rec )

#f1-measure
from sklearn.metrics import f1_score
f1=f1_score(y_test,predictions)
print("f1-measure  ",f1 )


########################




#### svm  ################
import pandas as pd
from sklearn import svm
data = pd.read_csv('classfiction.csv')

x=data.drop('outcome',1)
y=data['outcome']


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)


x=data.drop('outcome',1)
y=data['outcome']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)




classifiere = svm.SVC(kernel="rbf")
classifiere.fit(x_train,y_train)


predictions = classifiere.predict(x_test)



from sklearn.metrics import precision_score
pre=precision_score(y_test,predictions)
print("precision ", pre)


from sklearn.metrics import recall_score
rec=recall_score(y_test,predictions)
print("recall  ",rec )



from sklearn.metrics import f1_score
f1=f1_score(y_test,predictions)
print("f1-measure  ",f1 )


from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test,predictions)
print('accuracy_score =',acc)


###################################  missing value  ##########

mask.any(axis=1) ##row

mask.any(axis=0) ##colm

data[mask]
data[~mask]


##############  to clean data from missing ##############
mask=data.isnull().any(axis=1)
data_clean=data[~mask]


#############
data.isnull().sum()

##############

data.drop(columns=['name of colm'])


############

data.fill na({'x1':0})




